{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd5b0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10553a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images,test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13d990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = [np.reshape(x, -1) for x in train_images]\n",
    "test_images= [np.reshape(x, -1) for x in test_images]\n",
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984d7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_all_labels(data, num=100, minor=[]):\n",
    "    # this function is to limit the number of labels that are used\n",
    "    # it returns the indexes according the labels\n",
    "    # data is an array of labels\n",
    "    '''\n",
    "\n",
    "    :param data: array of labels\n",
    "    :param num: number required\n",
    "    :param minor: list of minority indexes\n",
    "    :return: array of labels indexes\n",
    "    '''\n",
    "\n",
    "    labels = np.unique(data)\n",
    "    co_l = []\n",
    "    if not minor:\n",
    "        for l in labels:\n",
    "            el_l = np.where(np.array(data) == l)\n",
    "            co_l.append(el_l[0])\n",
    "\n",
    "    else:\n",
    "        for l in labels:\n",
    "            if l in minor:\n",
    "                el_l = np.where(np.array(data) == l)\n",
    "                co_l.append((el_l[0])[:num])\n",
    "            else:\n",
    "                el_l = np.where(np.array(data) == l)\n",
    "                co_l.append(el_l[0])\n",
    "    return co_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3dfe126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 : number of samples : 2000\n",
      "class 1 : number of samples : 2000\n",
      "class 2 : number of samples : 5958\n",
      "class 3 : number of samples : 6131\n",
      "class 4 : number of samples : 5842\n",
      "class 5 : number of samples : 5421\n",
      "class 6 : number of samples : 5918\n",
      "class 7 : number of samples : 6265\n",
      "class 8 : number of samples : 5851\n",
      "class 9 : number of samples : 5949\n"
     ]
    }
   ],
   "source": [
    "grouped_labels = group_all_labels(train_labels, 2000, [0, 1])\n",
    "gr_data = []\n",
    "gr_labels = [] \n",
    "for index, q in enumerate(grouped_labels):\n",
    "    print('class {} : number of samples : {}'.format(index,len(q)))\n",
    "    for r in q:\n",
    "        gr_data.append(train_images[r])\n",
    "        gr_labels.append(train_labels[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4572ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2ed040fa30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_x = np.array(gr_data)\n",
    "train_x = (train_x.astype(np.float32) / 255.0) \n",
    "test_x =  np.array(test_images)\n",
    "test_images = (test_x.astype(np.float32)/255.0)\n",
    "train_y = tf.keras.utils.to_categorical(gr_labels, num_classes=10, dtype='float32')\n",
    "test_y = tf.keras.utils.to_categorical(test_labels, num_classes=10, dtype='float32')\n",
    "print(test_y[0])\n",
    "plt.imshow(np.reshape(test_x[0],(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feaee82",
   "metadata": {},
   "source": [
    "# Baseline RF with 1000 samples in class 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f482d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.56      0.82      0.67      1032\n",
      "           3       0.38      0.78      0.51      1010\n",
      "           4       0.73      0.73      0.73       982\n",
      "           5       0.54      0.11      0.18       892\n",
      "           6       0.63      0.89      0.74       958\n",
      "           7       0.47      0.90      0.62      1028\n",
      "           8       0.64      0.74      0.68       974\n",
      "           9       0.71      0.55      0.62      1009\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.46      0.55      0.47     10000\n",
      "weighted avg       0.46      0.55      0.47     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "baseline_rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "baseline_rf.fit(train_x, gr_labels)\n",
    "baseline_pred_y = baseline_rf.predict(test_x)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, baseline_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc85f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f223e14",
   "metadata": {},
   "source": [
    "#  VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de0d303c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-23 10:42:20.668167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-23 10:42:20.675328: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-23 10:42:20.676229: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-23 10:42:20.676854: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0 Loss: 755.0\n",
      "Iter: 1000 Loss: 148.2\n",
      "Iter: 2000 Loss: 132.3\n",
      "Iter: 3000 Loss: 115.4\n",
      "Iter: 4000 Loss: 114.4\n",
      "Iter: 5000 Loss: 112.4\n",
      "Iter: 6000 Loss: 114.4\n",
      "Iter: 7000 Loss: 108.2\n",
      "Iter: 8000 Loss: 107.6\n",
      "Iter: 9000 Loss: 110.9\n",
      "Iter: 10000 Loss: 113.9\n",
      "Iter: 11000 Loss: 105.3\n",
      "Iter: 12000 Loss: 111.7\n",
      "Iter: 13000 Loss: 103.8\n",
      "Iter: 14000 Loss: 108.6\n",
      "Iter: 15000 Loss: 106.7\n",
      "Iter: 16000 Loss: 102.0\n",
      "Iter: 17000 Loss: 109.4\n",
      "Iter: 18000 Loss: 104.9\n",
      "Iter: 19000 Loss: 107.8\n",
      "Iter: 20000 Loss: 110.0\n",
      "Iter: 21000 Loss: 110.5\n",
      "Iter: 22000 Loss: 106.9\n",
      "Iter: 23000 Loss: 109.0\n",
      "Iter: 24000 Loss: 109.8\n",
      "Iter: 25000 Loss: 107.9\n",
      "Iter: 26000 Loss: 104.8\n",
      "Iter: 27000 Loss: 107.5\n",
      "Iter: 28000 Loss: 104.6\n",
      "Iter: 29000 Loss: 107.4\n",
      "Iter: 30000 Loss: 109.4\n",
      "Iter: 31000 Loss: 110.7\n",
      "Iter: 32000 Loss: 108.0\n",
      "Iter: 33000 Loss: 107.8\n",
      "Iter: 34000 Loss: 104.4\n",
      "Iter: 35000 Loss: 108.6\n",
      "Iter: 36000 Loss: 105.8\n",
      "Iter: 37000 Loss: 104.0\n",
      "Iter: 38000 Loss: 105.9\n",
      "Iter: 39000 Loss: 107.4\n",
      "Iter: 40000 Loss: 109.4\n",
      "Iter: 41000 Loss: 109.6\n",
      "Iter: 42000 Loss: 103.6\n",
      "Iter: 43000 Loss: 100.8\n",
      "Iter: 44000 Loss: 100.3\n",
      "Iter: 45000 Loss: 102.7\n",
      "Iter: 46000 Loss: 105.5\n",
      "Iter: 47000 Loss: 106.3\n",
      "Iter: 48000 Loss: 106.2\n",
      "Iter: 49000 Loss: 108.0\n",
      "Iter: 50000 Loss: 107.9\n",
      "Iter: 51000 Loss: 99.46\n",
      "Iter: 52000 Loss: 111.3\n",
      "Iter: 53000 Loss: 103.0\n",
      "Iter: 54000 Loss: 106.2\n",
      "Iter: 55000 Loss: 104.5\n",
      "Iter: 56000 Loss: 106.7\n",
      "Iter: 57000 Loss: 105.9\n",
      "Iter: 58000 Loss: 105.6\n",
      "Iter: 59000 Loss: 107.5\n",
      "Iter: 60000 Loss: 107.2\n",
      "Iter: 61000 Loss: 105.7\n",
      "Iter: 62000 Loss: 104.4\n",
      "Iter: 63000 Loss: 107.4\n",
      "Iter: 64000 Loss: 103.2\n",
      "Iter: 65000 Loss: 104.8\n",
      "Iter: 66000 Loss: 113.8\n",
      "Iter: 67000 Loss: 104.6\n",
      "Iter: 68000 Loss: 111.3\n",
      "Iter: 69000 Loss: 105.2\n",
      "Iter: 70000 Loss: 106.2\n",
      "Iter: 71000 Loss: 105.1\n",
      "Iter: 72000 Loss: 104.9\n",
      "Iter: 73000 Loss: 106.9\n",
      "Iter: 74000 Loss: 103.8\n",
      "Iter: 75000 Loss: 108.1\n",
      "Iter: 76000 Loss: 112.3\n",
      "Iter: 77000 Loss: 108.3\n",
      "Iter: 78000 Loss: 102.5\n",
      "Iter: 79000 Loss: 106.0\n",
      "Iter: 80000 Loss: 103.8\n",
      "Iter: 81000 Loss: 105.6\n",
      "Iter: 82000 Loss: 104.9\n",
      "Iter: 83000 Loss: 106.1\n",
      "Iter: 84000 Loss: 106.3\n",
      "Iter: 85000 Loss: 103.5\n",
      "Iter: 86000 Loss: 97.33\n",
      "Iter: 87000 Loss: 102.7\n",
      "Iter: 88000 Loss: 101.6\n",
      "Iter: 89000 Loss: 107.1\n",
      "Iter: 90000 Loss: 105.3\n",
      "Iter: 91000 Loss: 110.2\n",
      "Iter: 92000 Loss: 101.2\n",
      "Iter: 93000 Loss: 102.7\n",
      "Iter: 94000 Loss: 109.9\n",
      "Iter: 95000 Loss: 102.1\n",
      "Iter: 96000 Loss: 98.4\n",
      "Iter: 97000 Loss: 99.13\n",
      "Iter: 98000 Loss: 106.3\n",
      "Iter: 99000 Loss: 102.7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "tf.disable_v2_behavior()\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mb_size = 64\n",
    "z_dim = 100\n",
    "X_dim = 784\n",
    "y_dim = 10\n",
    "h_dim = 128\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def plot(samples, sz, shape):\n",
    "    fig = plt.figure(figsize=(sz, sz))\n",
    "    gs = gridspec.GridSpec(sz, sz)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(shape, shape), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random.normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "# Q(z|X) \n",
    "\n",
    "X = tf.keras.Input(shape=(X_dim,))\n",
    "c = tf.keras.Input(shape=(y_dim,))\n",
    "z = tf.keras.Input(shape=(z_dim,))\n",
    "\n",
    "Q_W1 = tf.Variable(xavier_init([X_dim + y_dim, h_dim]))\n",
    "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "Q_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "Q_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "\n",
    "def Q(X, c):\n",
    "    inputs = tf.concat(axis=1, values=[X, c])\n",
    "    h = tf.nn.relu(tf.matmul(inputs, Q_W1) + Q_b1)\n",
    "    z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n",
    "    z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n",
    "    return z_mu, z_logvar\n",
    "\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = tf.random.normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(log_var / 2) * eps\n",
    "\n",
    "\n",
    "# P(X|z)\n",
    "\n",
    "P_W1 = tf.Variable(xavier_init([z_dim + y_dim, h_dim]))\n",
    "P_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "P_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "P_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "\n",
    "def P(z, c):\n",
    "    inputs = tf.concat(axis=1, values=[z, c])\n",
    "    h = tf.nn.relu(tf.matmul(inputs, P_W1) + P_b1)\n",
    "    logits = tf.matmul(h, P_W2) + P_b2\n",
    "    prob = tf.nn.sigmoid(logits)\n",
    "    return prob, logits\n",
    "\n",
    "z_mu, z_logvar = Q(X, c)\n",
    "z_sample = sample_z(z_mu, z_logvar)\n",
    "_, logits = P(z_sample, c)\n",
    "\n",
    "# Sampling from random z\n",
    "X_samples, _ = P(z, c)\n",
    "\n",
    "# E[log P(X|z)]\n",
    "recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X), 1)\n",
    "kl_loss = 0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "\n",
    "# VAE loss\n",
    "vae_loss = tf.reduce_mean(recon_loss + kl_loss)\n",
    "\n",
    "# gradient step\n",
    "solver = tf.compat.v1.train.AdamOptimizer().minimize(vae_loss)\n",
    "sess = tf.compat.v1.Session ()\n",
    "sess.run(\n",
    "tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('vae_mnist/'):\n",
    "    os.makedirs('vae_mnist/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(100000):\n",
    "    ind = np.random.choice(train_x.shape[0], mb_size)\n",
    "    X_mb = np.array(train_x[ind])\n",
    "    y_mb = np.array(train_y[ind])\n",
    "    \n",
    "    _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb, c: y_mb})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {:0} Loss: {:0.4}'.format(it, loss))\n",
    "        \n",
    "        samples=[]\n",
    "        for index in range(10):\n",
    "            y = np.zeros([y_dim, y_dim])\n",
    "            y[range(y_dim), index] = 1\n",
    "            samples.extend(sess.run(X_samples,\n",
    "                           feed_dict={z: np.random.randn(y_dim, z_dim), c: y}))\n",
    "\n",
    "        fig = plot(samples, 10, 28)\n",
    "        plt.savefig('vae_mnist/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b9f55e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d8022b880>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(samples[34],(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e067b26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7936, 784)\n",
      "(7936,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "gen_labels =[]\n",
    "for r in range(62):\n",
    "    for index in range(2):\n",
    "        gen_labels = gen_labels + [index]*64\n",
    "        y = np.zeros([mb_size, y_dim])\n",
    "        y[range(mb_size), index] = 1\n",
    "        samples.extend(sess.run(X_samples,\n",
    "                               feed_dict={z: np.random.randn(64, z_dim), c: y}))\n",
    "\n",
    "gen_samples = np.array(samples)\n",
    "gen_labels = np.array(gen_labels)\n",
    "print(gen_samples.shape)\n",
    "print(gen_labels.shape)\n",
    "print(gen_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3351b1",
   "metadata": {},
   "source": [
    "# Adding and classifying with generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84952a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(gen_samples[65],(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "np.save('mnist_gen_data.npy', gen_samples)\n",
    "np.save('mnist_gen_labels.npy', gen_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4c126c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73       980\n",
      "           1       0.53      0.28      0.36      1135\n",
      "           2       0.59      0.71      0.64      1032\n",
      "           3       0.45      0.69      0.54      1010\n",
      "           4       0.76      0.51      0.61       982\n",
      "           5       0.88      0.07      0.12       892\n",
      "           6       0.67      0.78      0.72       958\n",
      "           7       0.45      0.89      0.60      1028\n",
      "           8       0.69      0.50      0.58       974\n",
      "           9       0.58      0.62      0.60      1009\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.63      0.58      0.55     10000\n",
      "weighted avg       0.63      0.58      0.55     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([train_x, gen_samples])\n",
    "Y = np.concatenate([np.reshape(gr_labels, -1), gen_labels])\n",
    "\n",
    "aug_rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "aug_rf.fit(X, Y)\n",
    "aug_pred_y = aug_rf.predict(test_x)\n",
    "print(classification_report(test_labels, aug_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfccc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_aug = pd.DataFrame(classification_report(test_labels, aug_pred_y, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "821d9316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.756608</td>\n",
       "      <td>0.701020</td>\n",
       "      <td>0.727754</td>\n",
       "      <td>980.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.530405</td>\n",
       "      <td>0.276652</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1135.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585521</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.643076</td>\n",
       "      <td>1032.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447066</td>\n",
       "      <td>0.694059</td>\n",
       "      <td>0.543832</td>\n",
       "      <td>1010.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.758258</td>\n",
       "      <td>0.514257</td>\n",
       "      <td>0.612864</td>\n",
       "      <td>982.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.121086</td>\n",
       "      <td>892.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.779749</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>958.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.450442</td>\n",
       "      <td>0.892996</td>\n",
       "      <td>0.598826</td>\n",
       "      <td>1028.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.694286</td>\n",
       "      <td>0.498973</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>974.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.575646</td>\n",
       "      <td>0.618434</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>1009.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.5776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.634339</td>\n",
       "      <td>0.575434</td>\n",
       "      <td>0.550661</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.628627</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.551991</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.756608  0.701020  0.727754    980.0000\n",
       "1              0.530405  0.276652  0.363636   1135.0000\n",
       "2              0.585521  0.713178  0.643076   1032.0000\n",
       "3              0.447066  0.694059  0.543832   1010.0000\n",
       "4              0.758258  0.514257  0.612864    982.0000\n",
       "5              0.878788  0.065022  0.121086    892.0000\n",
       "6              0.666369  0.779749  0.718615    958.0000\n",
       "7              0.450442  0.892996  0.598826   1028.0000\n",
       "8              0.694286  0.498973  0.580645    974.0000\n",
       "9              0.575646  0.618434  0.596273   1009.0000\n",
       "accuracy       0.577600  0.577600  0.577600      0.5776\n",
       "macro avg      0.634339  0.575434  0.550661  10000.0000\n",
       "weighted avg   0.628627  0.577600  0.551991  10000.0000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_aug.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bcc3991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>980.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1135.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.558998</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.665359</td>\n",
       "      <td>1032.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.376853</td>\n",
       "      <td>0.780198</td>\n",
       "      <td>0.508223</td>\n",
       "      <td>1010.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.733198</td>\n",
       "      <td>0.733945</td>\n",
       "      <td>982.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.105381</td>\n",
       "      <td>0.176360</td>\n",
       "      <td>892.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.627941</td>\n",
       "      <td>0.891441</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>958.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.468464</td>\n",
       "      <td>0.895914</td>\n",
       "      <td>0.615230</td>\n",
       "      <td>1028.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.635961</td>\n",
       "      <td>0.737166</td>\n",
       "      <td>0.682834</td>\n",
       "      <td>974.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.706258</td>\n",
       "      <td>0.548067</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>1009.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.5496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.464940</td>\n",
       "      <td>0.551307</td>\n",
       "      <td>0.473598</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.457605</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.470418</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.000000  0.000000  0.000000    980.0000\n",
       "1              0.000000  0.000000  0.000000   1135.0000\n",
       "2              0.558998  0.821705  0.665359   1032.0000\n",
       "3              0.376853  0.780198  0.508223   1010.0000\n",
       "4              0.734694  0.733198  0.733945    982.0000\n",
       "5              0.540230  0.105381  0.176360    892.0000\n",
       "6              0.627941  0.891441  0.736842    958.0000\n",
       "7              0.468464  0.895914  0.615230   1028.0000\n",
       "8              0.635961  0.737166  0.682834    974.0000\n",
       "9              0.706258  0.548067  0.617188   1009.0000\n",
       "accuracy       0.549600  0.549600  0.549600      0.5496\n",
       "macro avg      0.464940  0.551307  0.473598  10000.0000\n",
       "weighted avg   0.457605  0.549600  0.470418  10000.0000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_orig = pd.DataFrame(classification_report(test_labels, baseline_pred_y, output_dict=True))\n",
    "pd_orig.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b02c7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pd = pd.merge(pd_orig.transpose(), pd_aug.transpose(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9cc7be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_x</th>\n",
       "      <th>recall_x</th>\n",
       "      <th>f1-score_x</th>\n",
       "      <th>support_x</th>\n",
       "      <th>precision_y</th>\n",
       "      <th>recall_y</th>\n",
       "      <th>f1-score_y</th>\n",
       "      <th>support_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>980.0000</td>\n",
       "      <td>0.756608</td>\n",
       "      <td>0.701020</td>\n",
       "      <td>0.727754</td>\n",
       "      <td>980.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1135.0000</td>\n",
       "      <td>0.530405</td>\n",
       "      <td>0.276652</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1135.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.558998</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.665359</td>\n",
       "      <td>1032.0000</td>\n",
       "      <td>0.585521</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.643076</td>\n",
       "      <td>1032.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.376853</td>\n",
       "      <td>0.780198</td>\n",
       "      <td>0.508223</td>\n",
       "      <td>1010.0000</td>\n",
       "      <td>0.447066</td>\n",
       "      <td>0.694059</td>\n",
       "      <td>0.543832</td>\n",
       "      <td>1010.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.733198</td>\n",
       "      <td>0.733945</td>\n",
       "      <td>982.0000</td>\n",
       "      <td>0.758258</td>\n",
       "      <td>0.514257</td>\n",
       "      <td>0.612864</td>\n",
       "      <td>982.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.105381</td>\n",
       "      <td>0.176360</td>\n",
       "      <td>892.0000</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.121086</td>\n",
       "      <td>892.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.627941</td>\n",
       "      <td>0.891441</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>958.0000</td>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.779749</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>958.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.468464</td>\n",
       "      <td>0.895914</td>\n",
       "      <td>0.615230</td>\n",
       "      <td>1028.0000</td>\n",
       "      <td>0.450442</td>\n",
       "      <td>0.892996</td>\n",
       "      <td>0.598826</td>\n",
       "      <td>1028.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.635961</td>\n",
       "      <td>0.737166</td>\n",
       "      <td>0.682834</td>\n",
       "      <td>974.0000</td>\n",
       "      <td>0.694286</td>\n",
       "      <td>0.498973</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>974.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.706258</td>\n",
       "      <td>0.548067</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>1009.0000</td>\n",
       "      <td>0.575646</td>\n",
       "      <td>0.618434</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>1009.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.5496</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.5776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.464940</td>\n",
       "      <td>0.551307</td>\n",
       "      <td>0.473598</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>0.634339</td>\n",
       "      <td>0.575434</td>\n",
       "      <td>0.550661</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.457605</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.470418</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>0.628627</td>\n",
       "      <td>0.577600</td>\n",
       "      <td>0.551991</td>\n",
       "      <td>10000.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision_x  recall_x  f1-score_x   support_x  precision_y  \\\n",
       "0                0.000000  0.000000    0.000000    980.0000     0.756608   \n",
       "1                0.000000  0.000000    0.000000   1135.0000     0.530405   \n",
       "2                0.558998  0.821705    0.665359   1032.0000     0.585521   \n",
       "3                0.376853  0.780198    0.508223   1010.0000     0.447066   \n",
       "4                0.734694  0.733198    0.733945    982.0000     0.758258   \n",
       "5                0.540230  0.105381    0.176360    892.0000     0.878788   \n",
       "6                0.627941  0.891441    0.736842    958.0000     0.666369   \n",
       "7                0.468464  0.895914    0.615230   1028.0000     0.450442   \n",
       "8                0.635961  0.737166    0.682834    974.0000     0.694286   \n",
       "9                0.706258  0.548067    0.617188   1009.0000     0.575646   \n",
       "accuracy         0.549600  0.549600    0.549600      0.5496     0.577600   \n",
       "macro avg        0.464940  0.551307    0.473598  10000.0000     0.634339   \n",
       "weighted avg     0.457605  0.549600    0.470418  10000.0000     0.628627   \n",
       "\n",
       "              recall_y  f1-score_y   support_y  \n",
       "0             0.701020    0.727754    980.0000  \n",
       "1             0.276652    0.363636   1135.0000  \n",
       "2             0.713178    0.643076   1032.0000  \n",
       "3             0.694059    0.543832   1010.0000  \n",
       "4             0.514257    0.612864    982.0000  \n",
       "5             0.065022    0.121086    892.0000  \n",
       "6             0.779749    0.718615    958.0000  \n",
       "7             0.892996    0.598826   1028.0000  \n",
       "8             0.498973    0.580645    974.0000  \n",
       "9             0.618434    0.596273   1009.0000  \n",
       "accuracy      0.577600    0.577600      0.5776  \n",
       "macro avg     0.575434    0.550661  10000.0000  \n",
       "weighted avg  0.577600    0.551991  10000.0000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32163e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
