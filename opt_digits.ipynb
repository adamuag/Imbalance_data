{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optical digits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_file = './uci_repos/optical_digits/optdigits.tra'\n",
    "test_file = './uci_repos/optical_digits/optdigits.tes'\n",
    "column = ['pixel_'+str(i) for i in range(64)]\n",
    "column.append('digit_label')\n",
    "train_data = pd.read_csv(train_file, sep=',', header=None, names=column)\n",
    "test_data = pd.read_csv(test_file, sep=',', header=None, names=column)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "test_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "      <th>digit_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0        0        0        5       13        9        1        0        0   \n",
       "1        0        0        0       12       13        5        0        0   \n",
       "2        0        0        0        4       15       12        0        0   \n",
       "3        0        0        7       15       13        1        0        0   \n",
       "4        0        0        0        1       11        0        0        0   \n",
       "\n",
       "   pixel_8  pixel_9  ...  pixel_55  pixel_56  pixel_57  pixel_58  pixel_59  \\\n",
       "0        0        0  ...         0         0         0         6        13   \n",
       "1        0        0  ...         0         0         0         0        11   \n",
       "2        0        0  ...         0         0         0         0         3   \n",
       "3        0        8  ...         0         0         0         7        13   \n",
       "4        0        0  ...         0         0         0         0         2   \n",
       "\n",
       "   pixel_60  pixel_61  pixel_62  pixel_63  digit_label  \n",
       "0        10         0         0         0            0  \n",
       "1        16        10         0         0            1  \n",
       "2        11        16         9         0            2  \n",
       "3        13         9         0         0            3  \n",
       "4        16         4         0         0            4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def group_all_labels(data, num=100, minor=[]):\n",
    "    # this function is to limit the number of labels that are used\n",
    "    # it returns the indexes according the labels\n",
    "    # data is an array of labels\n",
    "    '''\n",
    "\n",
    "    :param data: array of labels\n",
    "    :param num: number required\n",
    "    :param minor: list of minority indexes\n",
    "    :return: array of labels indexes\n",
    "    '''\n",
    "\n",
    "    labels = np.unique(data)\n",
    "    co_l = []\n",
    "    min_col =[]\n",
    "    if not minor:\n",
    "        for l in labels:\n",
    "            el_l = np.where(np.array(data) == l)\n",
    "            co_l.append(el_l[0])\n",
    "\n",
    "    else:\n",
    "        for l in labels:\n",
    "            if l in minor:\n",
    "                el_l = np.where(np.array(data) == l)\n",
    "                co_l.append((el_l[0])[:num])\n",
    "                min_col.append((el_l[0])[:num])\n",
    "            else:\n",
    "                el_l = np.where(np.array(data) == l)\n",
    "                co_l.append(el_l[0])\n",
    "    return co_l, min_col"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_y = train_data.iloc[:,-1:].copy().to_numpy()\n",
    "train_images = train_data.iloc[:, 0:-1].copy().to_numpy()\n",
    "y_test = test_data.iloc[:,-1:].copy().to_numpy()\n",
    "test_images = test_data.iloc[:, 0:-1].copy().to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "grouped_labels, min_label = group_all_labels(train_y, 100, [0, 1])\n",
    "gr_data = []\n",
    "gr_labels = [] \n",
    "for index, q in enumerate(grouped_labels):\n",
    "    print('class {} : number of samples : {}'.format(index,len(q)))\n",
    "    for r in q:\n",
    "        gr_data.append(train_images[r])\n",
    "        gr_labels.append(train_y[r])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "class 0 : number of samples : 100\n",
      "class 1 : number of samples : 100\n",
      "class 2 : number of samples : 380\n",
      "class 3 : number of samples : 389\n",
      "class 4 : number of samples : 387\n",
      "class 5 : number of samples : 376\n",
      "class 6 : number of samples : 377\n",
      "class 7 : number of samples : 387\n",
      "class 8 : number of samples : 380\n",
      "class 9 : number of samples : 382\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "np.unique(y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#train_images = [np.reshape(x, (8,8, 1)) for x in train_images ]\n",
    "train_images = np.array(gr_data).astype(np.float32) / 16.0\n",
    "#test_images = [np.reshape(x, (8,8, 1)) for x in test_images ]\n",
    "test_images = np.array(test_images).astype(np.float32) / 16.0\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(gr_labels, num_classes=10, dtype='float32')\n",
    "test_y = tf.keras.utils.to_categorical(y_test, num_classes=10, dtype='float32')\n",
    "print('train image size : ', train_images.shape)\n",
    "print('train y size : ', train_y.shape)\n",
    "print('test image size : ', test_images.shape)\n",
    "print('test y size : ', test_y.shape)\n",
    "print('sample y :', train_y[0])\n",
    "plt.imshow(np.reshape(train_images[100],(8,8)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train image size :  (3258, 64)\n",
      "train y size :  (3258, 10)\n",
      "test image size :  (1797, 64)\n",
      "test y size :  (1797, 10)\n",
      "sample y : [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6e16e9a1c0>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKeUlEQVR4nO3d32tf9R3H8ddrUdmcroG1DGlKkgspyGCJhIJ0iKs46hTdxS5aUFgZeDNF2UB0V+4fEHsxBKkawU7ZqlYRpxNUNmFztjXbbKOjKxlN0bVlFH/BSvW9i5xClXQ53/M9v/L2+YBgvj/IeX/VZ8/3e3J6Po4IAcjjK10PAKBeRA0kQ9RAMkQNJEPUQDIXNPFD165dGxMTE0386C+VTz75pLVtzc/Pt7atNWvWtLatycnJ1rYlSSMjI61sZ2FhQSdPnvRyjzUS9cTEhPbt29fEj/5SmZuba21b09PTrW3rmmuuaW1bs7OzrW1LkkZHR1vZzszMzHkf4+03kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBMqahtb7X9ru3Dtu9peigA1a0Yte0RSb+SdL2kKyRtt31F04MBqKbMnnqTpMMRcSQiTkt6UtLNzY4FoKoyUa+XdPSc24vFfZ9j+zbb+2zvO3HiRF3zARhQbQfKIuKhiJiJiJl169bV9WMBDKhM1MckbTjn9lhxH4AeKhP1m5Iutz1p+yJJ2yQ91+xYAKpa8SIJEXHG9u2SXpI0IumRiDjY+GQAKil15ZOIeEHSCw3PAqAGnFEGJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJNPICh2ox969e7seoRHPPvts1yOkxp4aSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkyqzQ8Yjt47bfbmMgAMMps6eelbS14TkA1GTFqCPiD5L+08IsAGpQ22dqlt0B+oFld4BkOPoNJEPUQDJlfqX1hKQ/Sdpoe9H2T5ofC0BVZdbS2t7GIADqwdtvIBmiBpIhaiAZogaSIWogGaIGkiFqIBmW3emxU6dOdT1CI8bHx1vb1ujoaGvb6gv21EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJFPmGmUbbL9q+5Dtg7bvbGMwANWUOff7jKSfR8QB25dK2m/75Yg41PBsACoos+zOexFxoPj+Q0nzktY3PRiAagb6TG17QtK0pDeWeYxld4AeKB217UskPSXproj44IuPs+wO0A+lorZ9oZaC3h0RTzc7EoBhlDn6bUkPS5qPiPubHwnAMMrsqTdLulXSFttzxdcPGp4LQEVllt15XZJbmAVADTijDEiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkVv1aWm2uNzU7O9vatiRp586drW6vLVNTU12PkBp7aiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogmTIXHvyq7b/Y/mux7M4v2xgMQDVlThP9r6QtEfFRcang123/LiL+3PBsACooc+HBkPRRcfPC4iuaHApAdWUv5j9ie07ScUkvRwTL7gA9VSrqiPg0IqYkjUnaZPvbyzyHZXeAHhjo6HdEnJL0qqStjUwDYGhljn6vsz1afP81SddJeqfhuQBUVObo92WSHrM9oqU/BH4TEc83OxaAqsoc/f6bltakBrAKcEYZkAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8ms+mV37rvvvta2lXUZnLax7E6z2FMDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBM6aiLC/q/ZZuLDgI9Nsie+k5J800NAqAeZZfdGZN0g6RdzY4DYFhl99QPSLpb0mfnewJraQH9UGaFjhslHY+I/f/veaylBfRDmT31Zkk32V6Q9KSkLbYfb3QqAJWtGHVE3BsRYxExIWmbpFci4pbGJwNQCb+nBpIZ6HJGEfGapNcamQRALdhTA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8mw7M4ARkdHW9uWJE1MTLS2rR07drS2rbb/PX7ZsKcGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiCZUqeJFlcS/VDSp5LORMRMk0MBqG6Qc7+/FxEnG5sEQC14+w0kUzbqkPR72/tt37bcE1h2B+iHslF/NyKulHS9pJ/avvqLT2DZHaAfSkUdEceKfx6X9IykTU0OBaC6Mgvkfd32pWe/l/R9SW83PRiAasoc/f6WpGdsn33+ryPixUanAlDZilFHxBFJ32lhFgA14FdaQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDKrftmdNpdwaXOJH0nau3dvq9try8LCQtcjpMaeGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZEpFbXvU9h7b79iet31V04MBqKbsud87Jb0YET+yfZGkixucCcAQVoza9hpJV0v6sSRFxGlJp5sdC0BVZd5+T0o6IelR22/Z3lVc//tzWHYH6IcyUV8g6UpJD0bEtKSPJd3zxSex7A7QD2WiXpS0GBFvFLf3aClyAD20YtQR8b6ko7Y3FnddK+lQo1MBqKzs0e87JO0ujnwfkbSjuZEADKNU1BExJ2mm2VEA1IEzyoBkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIZtWvpZXZ1NRUa9saHx9vbVttrhHW9vpnba7tdj7sqYFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZFaM2vZG23PnfH1g+64WZgNQwYqniUbEu5KmJMn2iKRjkp5pdiwAVQ369vtaSf+MiH81MQyA4Q0a9TZJTyz3AMvuAP1QOurimt83Sfrtco+z7A7QD4Psqa+XdCAi/t3UMACGN0jU23Wet94A+qNU1MXStddJerrZcQAMq+yyOx9L+mbDswCoAWeUAckQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZCMI6L+H2qfkDToX89cK+lk7cP0Q9bXxuvqznhELPs3pxqJugrb+yJipus5mpD1tfG6+om330AyRA0k06eoH+p6gAZlfW28rh7qzWdqAPXo054aQA2IGkimF1Hb3mr7XduHbd/T9Tx1sL3B9qu2D9k+aPvOrmeqk+0R22/Zfr7rWepke9T2Htvv2J63fVXXMw2q88/UxQIB/9DS5ZIWJb0paXtEHOp0sCHZvkzSZRFxwPalkvZL+uFqf11n2f6ZpBlJ34iIG7uepy62H5P0x4jYVVxB9+KIONXxWAPpw556k6TDEXEkIk5LelLSzR3PNLSIeC8iDhTffyhpXtL6bqeqh+0xSTdI2tX1LHWyvUbS1ZIelqSIOL3agpb6EfV6SUfPub2oJP/zn2V7QtK0pDc6HqUuD0i6W9JnHc9Rt0lJJyQ9Wny02FVcdHNV6UPUqdm+RNJTku6KiA+6nmdYtm+UdDwi9nc9SwMukHSlpAcjYlrSx5JW3TGePkR9TNKGc26PFfeterYv1FLQuyMiy+WVN0u6yfaClj4qbbH9eLcj1WZR0mJEnH1HtUdLka8qfYj6TUmX254sDkxsk/RcxzMNzba19NlsPiLu73qeukTEvRExFhETWvpv9UpE3NLxWLWIiPclHbW9sbjrWkmr7sBmqet+Nykizti+XdJLkkYkPRIRBzseqw6bJd0q6e+254r7fhERL3Q3Ekq4Q9LuYgdzRNKOjucZWOe/0gJQrz68/QZQI6IGkiFqIBmiBpIhaiAZogaSIWogmf8BMQyXsQkmOvYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VAE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "tf.disable_v2_behavior()\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mb_size = 64\n",
    "z_dim = 10\n",
    "X_dim = 64\n",
    "y_dim = 10\n",
    "h_dim = 16\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(8, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(8, 8), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random.normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "# Q(z|X) \n",
    "\n",
    "X = tf.keras.Input(shape=(X_dim,))\n",
    "c = tf.keras.Input(shape=(y_dim,))\n",
    "z = tf.keras.Input(shape=(z_dim,))\n",
    "\n",
    "Q_W1 = tf.Variable(xavier_init([X_dim + y_dim, h_dim]))\n",
    "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "Q_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "Q_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "\n",
    "def Q(X, c):\n",
    "    inputs = tf.concat(axis=1, values=[X, c])\n",
    "    h = tf.nn.relu(tf.matmul(inputs, Q_W1) + Q_b1)\n",
    "    z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n",
    "    z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n",
    "    return z_mu, z_logvar\n",
    "\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = tf.random.normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(log_var / 2) * eps\n",
    "\n",
    "\n",
    "# P(X|z)\n",
    "\n",
    "P_W1 = tf.Variable(xavier_init([z_dim + y_dim, h_dim]))\n",
    "P_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "P_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "P_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "\n",
    "def P(z, c):\n",
    "    inputs = tf.concat(axis=1, values=[z, c])\n",
    "    h = tf.nn.relu(tf.matmul(inputs, P_W1) + P_b1)\n",
    "    logits = tf.matmul(h, P_W2) + P_b2\n",
    "    prob = tf.nn.sigmoid(logits)\n",
    "    return prob, logits\n",
    "\n",
    "z_mu, z_logvar = Q(X, c)\n",
    "z_sample = sample_z(z_mu, z_logvar)\n",
    "_, logits = P(z_sample, c)\n",
    "\n",
    "# Sampling from random z\n",
    "X_samples, _ = P(z, c)\n",
    "\n",
    "# E[log P(X|z)]\n",
    "recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X), 1)\n",
    "kl_loss = 0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "\n",
    "# VAE loss\n",
    "vae_loss = tf.reduce_mean(recon_loss + kl_loss)\n",
    "\n",
    "# gradient step\n",
    "solver = tf.compat.v1.train.AdamOptimizer().minimize(vae_loss)\n",
    "sess = tf.compat.v1.Session ()\n",
    "sess.run(\n",
    "tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('samples_opt_100/'):\n",
    "    os.makedirs('samples_opt_100/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(100000):\n",
    "    ind = np.random.choice(train_images.shape[0], mb_size)\n",
    "    X_mb = np.array(train_images[ind])\n",
    "    y_mb = np.array(train_y[ind])\n",
    "    \n",
    "    _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb, c: y_mb})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {:.2}'. format(loss))\n",
    "        print()\n",
    "\n",
    "        y = np.zeros(shape=[64, y_dim])\n",
    "        y[:, np.random.randint(0, y_dim)] = 1.\n",
    "\n",
    "        samples = sess.run(X_samples,\n",
    "                           feed_dict={z: np.random.randn(64, z_dim), c: y})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('samples_opt_100/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-03 23:54:59.735700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-03 23:55:00.056940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-03 23:55:00.095868: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-10-03 23:55:00.097682: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iter: 0\n",
      "Loss: 6e+01\n",
      "\n",
      "Iter: 1000\n",
      "Loss: 2.4e+01\n",
      "\n",
      "Iter: 2000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 3000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 4000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 5000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 6000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 7000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 8000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 9000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 10000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 11000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 12000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 13000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 14000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 15000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 16000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 17000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 18000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 19000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 20000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 21000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 22000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 23000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 24000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 25000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 26000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 27000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 28000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 29000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 30000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 31000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 32000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 33000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 34000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 35000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 36000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 37000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 38000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 39000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 40000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 41000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 42000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 43000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 44000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 45000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 46000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 47000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 48000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 49000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 50000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 51000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 52000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 53000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 54000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 55000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 56000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 57000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 58000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 59000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 60000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 61000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 62000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 63000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 64000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 65000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 66000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 67000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 68000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 69000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 70000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 71000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 72000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 73000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 74000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 75000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 76000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 77000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 78000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 79000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 80000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 81000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 82000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 83000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 84000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 85000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 86000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 87000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 88000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 89000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 90000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 91000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 92000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 93000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 94000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 95000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 96000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 97000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 98000\n",
      "Loss: 2.3e+01\n",
      "\n",
      "Iter: 99000\n",
      "Loss: 2.2e+01\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "### generating sample outputs after training\n",
    "samples = []\n",
    "gen_labels =[]\n",
    "for r in range(10):\n",
    "    for index in range(2):\n",
    "        gen_labels = gen_labels + [index]*64\n",
    "        y = np.zeros([mb_size, y_dim])\n",
    "        y[range(mb_size), index] = 1\n",
    "        samples.extend(sess.run(X_samples,\n",
    "                               feed_dict={z: np.random.randn(64, z_dim), c: y}))\n",
    "\n",
    "gen_samples = np.array(samples)\n",
    "gen_labels = np.array(gen_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "gen_samples.shape, gen_labels.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1280, 64), (1280,))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(gen_labels[70])\n",
    "plt.imshow(np.reshape(gen_samples[70],(8,8)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6d16ae6c10>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# np.save('gen_data.npy', gen_samples)\n",
    "# np.save('gen_labels.npy', gen_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# normiziling pixel between 0..16 similar to the original data.\n",
    "norm_xtrain = (16*(gen_samples - np.min(gen_samples))/np.ptp(gen_samples)).astype(int) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "def build_model(input_shape=(64,), num_classes=10):\n",
    "    \"\"\"\n",
    "\n",
    "    :param input_shape: shape of input_data\n",
    "    :param num_classes: number of classes\n",
    "    :return: keras.model.sequential compiled with categorical cross-entropy loss\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model = build_model()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X = np.concatenate([train_images, gen_samples])\n",
    "gen_y = tf.keras.utils.to_categorical(gen_labels, num_classes=10, dtype='float32')\n",
    "Y = np.concatenate([train_y, gen_y])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "batch_size=8\n",
    "epochs=2\n",
    "history = model.fit(train_images, train_y, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_y))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 3258 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "3258/3258 [==============================] - 1s 305us/sample - loss: 1.5113 - acc: 0.5319 - val_loss: 0.6041 - val_acc: 0.8319\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2/2\n",
      "3258/3258 [==============================] - 1s 227us/sample - loss: 0.6915 - acc: 0.7830 - val_loss: 0.3801 - val_acc: 0.8820\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "score = model.evaluate(test_images, test_y, verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "print('test loss: ',score[0])\n",
    "print('test accuracy: ', score[1] )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test loss:  0.3801463360571171\n",
      "test accuracy:  0.8820256\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "history.history.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "y_pred_oh = model.predict(test_images)\n",
    "y_pred_baseline = y_pred_oh.argmax(axis=-1)\n",
    "y_pred_baseline"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 8, ..., 8, 9, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('MLP classification report\\n',classification_report(y_test, y_pred_baseline))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLP classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       178\n",
      "           1       0.99      0.38      0.55       182\n",
      "           2       0.88      0.98      0.93       177\n",
      "           3       0.94      0.84      0.89       183\n",
      "           4       0.94      0.98      0.96       181\n",
      "           5       0.91      0.97      0.94       182\n",
      "           6       0.92      0.98      0.95       181\n",
      "           7       0.88      0.92      0.90       179\n",
      "           8       0.67      0.93      0.78       174\n",
      "           9       0.84      0.88      0.86       180\n",
      "\n",
      "    accuracy                           0.88      1797\n",
      "   macro avg       0.90      0.88      0.87      1797\n",
      "weighted avg       0.90      0.88      0.87      1797\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on combined generated and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "print(len(Y))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4538\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "model_aug = build_model()\n",
    "# X_train = np.array(X).astype(np.float32) / 16.0\n",
    "# Y_oh = np.array(tf.keras.utils.to_categorical(Y, num_classes=10, dtype='float32'))\n",
    "history_aug = model_aug.fit(X, Y, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_y))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4538/4538 [==============================] - ETA: 0s - loss: 1.0544 - acc: 0.6792"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4538/4538 [==============================] - 1s 248us/sample - loss: 1.0544 - acc: 0.6792 - val_loss: 0.4443 - val_acc: 0.8603\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 229us/sample - loss: 0.4582 - acc: 0.8676 - val_loss: 0.3142 - val_acc: 0.8971\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "y_pred_aug_oh = model_aug.predict(test_images)\n",
    "y_pred_aug = y_pred_aug_oh.argmax(axis=-1)\n",
    "print('Combined MLP classification report on real samples only.\\n',classification_report(y_test, y_pred_aug))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combined MLP classification report on real samples only.\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       178\n",
      "           1       0.94      0.52      0.67       182\n",
      "           2       0.87      0.98      0.92       177\n",
      "           3       0.91      0.91      0.91       183\n",
      "           4       0.93      0.98      0.95       181\n",
      "           5       0.86      0.96      0.91       182\n",
      "           6       0.95      0.98      0.97       181\n",
      "           7       0.97      0.91      0.94       179\n",
      "           8       0.73      0.89      0.80       174\n",
      "           9       0.87      0.87      0.87       180\n",
      "\n",
      "    accuracy                           0.90      1797\n",
      "   macro avg       0.90      0.90      0.89      1797\n",
      "weighted avg       0.90      0.90      0.89      1797\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('imbalance_venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "4726aa8c3a011139ee9eae324612f94ded5d9a6c6a3363e2331a9b86c3055c02"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}