{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c34b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c343cf9",
   "metadata": {},
   "source": [
    "## Optical digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521c35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './uci_repos/optical_digits/optdigits.tra'\n",
    "test_file = './uci_repos/optical_digits/optdigits.tes'\n",
    "column = ['pixel_'+str(i) for i in range(64)]\n",
    "column.append('digit_label')\n",
    "train_data = pd.read_csv(train_file, sep=',', header=None, names=column)\n",
    "test_data = pd.read_csv(test_file, sep=',', header=None, names=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336d550e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "      <th>digit_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0        0        0        5       13        9        1        0        0   \n",
       "1        0        0        0       12       13        5        0        0   \n",
       "2        0        0        0        4       15       12        0        0   \n",
       "3        0        0        7       15       13        1        0        0   \n",
       "4        0        0        0        1       11        0        0        0   \n",
       "\n",
       "   pixel_8  pixel_9  ...  pixel_55  pixel_56  pixel_57  pixel_58  pixel_59  \\\n",
       "0        0        0  ...         0         0         0         6        13   \n",
       "1        0        0  ...         0         0         0         0        11   \n",
       "2        0        0  ...         0         0         0         0         3   \n",
       "3        0        8  ...         0         0         0         7        13   \n",
       "4        0        0  ...         0         0         0         0         2   \n",
       "\n",
       "   pixel_60  pixel_61  pixel_62  pixel_63  digit_label  \n",
       "0        10         0         0         0            0  \n",
       "1        16        10         0         0            1  \n",
       "2        11        16         9         0            2  \n",
       "3        13         9         0         0            3  \n",
       "4        16         4         0         0            4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0639d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data.iloc[:,-1:].copy().to_numpy()\n",
    "train_images = train_data.iloc[:, 0:-1].copy().to_numpy()\n",
    "test_y = test_data.iloc[:,-1:].copy().to_numpy()\n",
    "test_images = test_data.iloc[:, 0:-1].copy().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "779e9351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d440b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image size :  (3823, 64)\n",
      "train y size :  (3823, 10)\n",
      "test image size :  (1797, 64)\n",
      "test y size :  (1797, 10)\n",
      "sample y : [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcd6a3ed520>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_images = [np.reshape(x, (8,8, 1)) for x in train_images ]\n",
    "train_images = np.array(train_images).astype(np.float32) / 16.0\n",
    "#test_images = [np.reshape(x, (8,8, 1)) for x in test_images ]\n",
    "test_images = np.array(test_images).astype(np.float32) / 16.0\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(train_y, num_classes=10, dtype='float32')\n",
    "test_y = tf.keras.utils.to_categorical(test_y, num_classes=10, dtype='float32')\n",
    "print('train image size : ', train_images.shape)\n",
    "print('train y size : ', train_y.shape)\n",
    "print('test image size : ', test_images.shape)\n",
    "print('test y size : ', test_y.shape)\n",
    "print('sample y :', train_y[0])\n",
    "plt.imshow(np.reshape(train_images[100],(8,8)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce0ea4",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4630d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 09:31:04.379451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-27 09:31:04.397544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-09-27 09:31:04.399897: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-27 09:31:04.401606: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Loss: 6.1e+01\n",
      "\n",
      "Iter: 1000\n",
      "Loss: 2.4e+01\n",
      "\n",
      "Iter: 2000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 3000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 4000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 5000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 6000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 7000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 8000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 9000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 10000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 11000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 12000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 13000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 14000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 15000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 16000\n",
      "Loss: 2e+01\n",
      "\n",
      "Iter: 17000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 18000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 19000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 20000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 21000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 22000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 23000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 24000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 25000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 26000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 27000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 28000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 29000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 30000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 31000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 32000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 33000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 34000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 35000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 36000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 37000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 38000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 39000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 40000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 41000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 42000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 43000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 44000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 45000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 46000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 47000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 48000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 49000\n",
      "Loss: 2e+01\n",
      "\n",
      "Iter: 50000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 51000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 52000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 53000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 54000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 55000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 56000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 57000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 58000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 59000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 60000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 61000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 62000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 63000\n",
      "Loss: 2e+01\n",
      "\n",
      "Iter: 64000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 65000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 66000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 67000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 68000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 69000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 70000\n",
      "Loss: 2e+01\n",
      "\n",
      "Iter: 71000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 72000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 73000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 74000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 75000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 76000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 77000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 78000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 79000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 80000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 81000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 82000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 83000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 84000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 85000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 86000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 87000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 88000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 89000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 90000\n",
      "Loss: 2e+01\n",
      "\n",
      "Iter: 91000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 92000\n",
      "Loss: 2.2e+01\n",
      "\n",
      "Iter: 93000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 94000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 95000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 96000\n",
      "Loss: 2e+01\n",
      "\n",
      "Iter: 97000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 98000\n",
      "Loss: 2.1e+01\n",
      "\n",
      "Iter: 99000\n",
      "Loss: 2.2e+01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "tf.disable_v2_behavior()\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mb_size = 64\n",
    "z_dim = 10\n",
    "X_dim = 64\n",
    "y_dim = 10\n",
    "h_dim = 16\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(8, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(8, 8), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random.normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "# Q(z|X) \n",
    "\n",
    "X = tf.keras.Input(shape=(X_dim,))\n",
    "c = tf.keras.Input(shape=(y_dim,))\n",
    "z = tf.keras.Input(shape=(z_dim,))\n",
    "\n",
    "Q_W1 = tf.Variable(xavier_init([X_dim + y_dim, h_dim]))\n",
    "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "Q_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "Q_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "\n",
    "def Q(X, c):\n",
    "    inputs = tf.concat(axis=1, values=[X, c])\n",
    "    h = tf.nn.relu(tf.matmul(inputs, Q_W1) + Q_b1)\n",
    "    z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n",
    "    z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n",
    "    return z_mu, z_logvar\n",
    "\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = tf.random.normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(log_var / 2) * eps\n",
    "\n",
    "\n",
    "# P(X|z)\n",
    "\n",
    "P_W1 = tf.Variable(xavier_init([z_dim + y_dim, h_dim]))\n",
    "P_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "P_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "P_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "\n",
    "def P(z, c):\n",
    "    inputs = tf.concat(axis=1, values=[z, c])\n",
    "    h = tf.nn.relu(tf.matmul(inputs, P_W1) + P_b1)\n",
    "    logits = tf.matmul(h, P_W2) + P_b2\n",
    "    prob = tf.nn.sigmoid(logits)\n",
    "    return prob, logits\n",
    "\n",
    "z_mu, z_logvar = Q(X, c)\n",
    "z_sample = sample_z(z_mu, z_logvar)\n",
    "_, logits = P(z_sample, c)\n",
    "\n",
    "# Sampling from random z\n",
    "X_samples, _ = P(z, c)\n",
    "\n",
    "# E[log P(X|z)]\n",
    "recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X), 1)\n",
    "kl_loss = 0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "\n",
    "# VAE loss\n",
    "vae_loss = tf.reduce_mean(recon_loss + kl_loss)\n",
    "\n",
    "# gradient step\n",
    "solver = tf.compat.v1.train.AdamOptimizer().minimize(vae_loss)\n",
    "sess = tf.compat.v1.Session ()\n",
    "sess.run(\n",
    "tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('samples/'):\n",
    "    os.makedirs('samples/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(100000):\n",
    "    ind = np.random.choice(train_images.shape[0], mb_size)\n",
    "    X_mb = np.array(train_images[ind])\n",
    "    y_mb = np.array(train_y[ind])\n",
    "    \n",
    "    _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb, c: y_mb})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {:.2}'. format(loss))\n",
    "        print()\n",
    "\n",
    "        y = np.zeros(shape=[64, y_dim])\n",
    "        y[:, np.random.randint(0, y_dim)] = 1.\n",
    "\n",
    "        samples = sess.run(X_samples,\n",
    "                           feed_dict={z: np.random.randn(64, z_dim), c: y})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('samples/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6159d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "### generating sample outputs after training\n",
    "samples = []\n",
    "gen_labels =[]\n",
    "for r in range(10):\n",
    "    for index in range(10):\n",
    "        gen_labels = gen_labels + [index]*64\n",
    "        y = np.zeros([mb_size, y_dim])\n",
    "        y[range(mb_size), index] = 1\n",
    "        samples.extend(sess.run(X_samples,\n",
    "                               feed_dict={z: np.random.randn(64, z_dim), c: y}))\n",
    "\n",
    "gen_samples = np.array(samples)\n",
    "gen_labels = np.array(gen_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634a9601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400, 64), (6400,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_samples.shape, gen_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd8559f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0669617e-12, 1.8530786e-03, 2.4398842e-01, 8.1747741e-01,\n",
       "       6.7669809e-01, 1.3874090e-01, 1.3165474e-03, 1.9649071e-05,\n",
       "       7.6706579e-07, 6.4194471e-02, 8.0486488e-01, 8.3133286e-01,\n",
       "       7.7804649e-01, 6.7142594e-01, 3.3711225e-02, 1.1848686e-04,\n",
       "       2.0694735e-07, 2.2574890e-01, 8.9809781e-01, 3.2849234e-01,\n",
       "       1.9830623e-01, 7.9445273e-01, 1.9700915e-01, 1.0958515e-04,\n",
       "       1.7301841e-14, 2.9412645e-01, 7.9006112e-01, 1.1294222e-01,\n",
       "       1.6506076e-02, 5.7117260e-01, 3.9789921e-01, 1.7638837e-06,\n",
       "       9.5837628e-16, 3.0764961e-01, 7.5302339e-01, 6.4066380e-02,\n",
       "       6.0657263e-03, 5.3396338e-01, 4.5765975e-01, 4.5688036e-14,\n",
       "       2.9337069e-31, 1.7829180e-01, 8.5281408e-01, 1.2649879e-01,\n",
       "       8.4978938e-02, 7.0364541e-01, 4.1869769e-01, 6.6120170e-05,\n",
       "       1.1590689e-08, 4.1935652e-02, 8.1570995e-01, 6.7624474e-01,\n",
       "       6.7406070e-01, 8.3523703e-01, 1.7990944e-01, 3.1057000e-04,\n",
       "       7.3946188e-13, 2.0355582e-03, 2.5083691e-01, 8.3951068e-01,\n",
       "       8.3870268e-01, 3.5633728e-01, 1.6131699e-02, 2.0855665e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57cb2663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcc69fdc970>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(gen_labels[70])\n",
    "plt.imshow(np.reshape(gen_samples[70],(8,8)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b67807",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('gen_data.npy', gen_samples)\n",
    "np.save('gen_labels.npy', gen_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22186505",
   "metadata": {},
   "source": [
    "# 1. Experimenting on original samples only with RF (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe10281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "y_train = train_data.iloc[:,-1:].copy().to_numpy()\n",
    "x_train = train_data.iloc[:, 0:-1].copy().to_numpy()\n",
    "y_test = test_data.iloc[:,-1:].copy().to_numpy()\n",
    "x_test = test_data.iloc[:, 0:-1].copy().to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cdcff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10476/147419484.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(x_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.800222593210907"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train, y_train)\n",
    "rf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b47b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "680de251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       178\n",
      "           1       0.77      0.43      0.55       182\n",
      "           2       0.76      0.84      0.79       177\n",
      "           3       0.71      0.90      0.79       183\n",
      "           4       0.88      0.81      0.84       181\n",
      "           5       0.93      0.71      0.81       182\n",
      "           6       0.80      0.97      0.88       181\n",
      "           7       0.75      0.92      0.83       179\n",
      "           8       0.74      0.65      0.69       174\n",
      "           9       0.80      0.78      0.79       180\n",
      "\n",
      "    accuracy                           0.80      1797\n",
      "   macro avg       0.81      0.80      0.79      1797\n",
      "weighted avg       0.81      0.80      0.79      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2a38bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 10, 16,  6,  0,  0,  0,  0,  7, 16,  8, 16,  5,  0,  0,  0,\n",
       "       11, 16,  0,  6, 14,  3,  0,  0, 12, 12,  0,  0, 11, 11,  0,  0, 12,\n",
       "       12,  0,  0,  8, 12,  0,  0,  7, 15,  1,  0, 13, 11,  0,  0,  0, 16,\n",
       "        8, 10, 15,  3,  0,  0,  0, 10, 16, 15,  3,  0,  0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9272360",
   "metadata": {},
   "source": [
    "## 2. Generated samples classification (only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee53e59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_gentrain,x_gentest, y_gentrain, y_gentest = train_test_split(\n",
    "    gen_samples, gen_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "rf1 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf1.fit(x_gentrain, y_gentrain)\n",
    "rf1.score(x_gentest, y_gentest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "569f34f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      0.92      0.96       180\n",
      "           2       0.99      1.00      1.00       150\n",
      "           3       1.00      1.00      1.00       171\n",
      "           4       1.00      1.00      1.00       142\n",
      "           5       0.98      0.98      0.98       154\n",
      "           6       1.00      1.00      1.00       167\n",
      "           7       1.00      1.00      1.00       155\n",
      "           8       0.98      1.00      0.99       159\n",
      "           9       0.94      1.00      0.97       158\n",
      "\n",
      "    accuracy                           0.99      1600\n",
      "   macro avg       0.99      0.99      0.99      1600\n",
      "weighted avg       0.99      0.99      0.99      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_ygen = rf1.predict(x_gentest)\n",
    "print(classification_report(y_gentest, pred_ygen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d9855",
   "metadata": {},
   "source": [
    "## Discussion (Why High Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cdb212",
   "metadata": {},
   "source": [
    "The classification result on generated samples appeared higher by over 18 %. Next we try to normalize pixels before classification just to cverify that the results are not affected by the pixel values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25586451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normiziling pixel between 0..16 similar to the original data.\n",
    "norm_xtrain = (16*(x_gentrain - np.min(x_gentrain))/np.ptp(x_gentrain)).astype(int) \n",
    "norm_xtest = (16*(x_gentest - np.min(x_gentest))/np.ptp(x_gentest)).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d56bbf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcc66bb8820>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_gentrain[1008])\n",
    "plt.imshow(np.reshape(norm_xtrain[1008],(8,8)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bc30212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.991875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf2.fit(norm_xtrain, y_gentrain)\n",
    "rf2.score(norm_xtest, y_gentest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f21966e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      0.96      0.98       180\n",
      "           2       0.99      1.00      1.00       150\n",
      "           3       1.00      1.00      1.00       171\n",
      "           4       0.96      0.98      0.97       142\n",
      "           5       0.99      0.99      0.99       154\n",
      "           6       0.99      1.00      1.00       167\n",
      "           7       0.99      1.00      0.99       155\n",
      "           8       1.00      0.99      1.00       159\n",
      "           9       0.99      1.00      0.99       158\n",
      "\n",
      "    accuracy                           0.99      1600\n",
      "   macro avg       0.99      0.99      0.99      1600\n",
      "weighted avg       0.99      0.99      0.99      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_norm = rf2.predict(norm_xtest)\n",
    "print(classification_report(y_gentest, pred_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba751d63",
   "metadata": {},
   "source": [
    "The results appeared unchanged. Thus, pixel values/norm had zero effect on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7c1c2",
   "metadata": {},
   "source": [
    "## 3.  Trained on real testing on generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89c73130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy :  0.93375\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy : ', rf.score(norm_xtest, y_gentest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62a3544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      0.78      0.88       180\n",
      "           2       0.97      1.00      0.99       150\n",
      "           3       0.76      1.00      0.86       171\n",
      "           4       0.96      0.91      0.93       142\n",
      "           5       1.00      0.66      0.80       154\n",
      "           6       0.93      1.00      0.96       167\n",
      "           7       0.92      1.00      0.96       155\n",
      "           8       0.90      0.99      0.95       159\n",
      "           9       1.00      0.99      1.00       158\n",
      "\n",
      "    accuracy                           0.93      1600\n",
      "   macro avg       0.94      0.93      0.93      1600\n",
      "weighted avg       0.94      0.93      0.93      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_norm3 = rf.predict(norm_xtest)\n",
    "print(classification_report(y_gentest, pred_norm3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9b172",
   "metadata": {},
   "source": [
    "## 4. Trained on generated --> testing on real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6647a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy :  0.7590428491930996\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy : ', rf2.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "336105dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.98      0.82       178\n",
      "           1       0.80      0.59      0.68       182\n",
      "           2       0.63      0.89      0.74       177\n",
      "           3       0.81      0.79      0.80       183\n",
      "           4       0.80      0.87      0.83       181\n",
      "           5       0.74      0.76      0.75       182\n",
      "           6       0.82      0.96      0.89       181\n",
      "           7       0.74      0.93      0.82       179\n",
      "           8       0.89      0.43      0.58       174\n",
      "           9       0.84      0.39      0.53       180\n",
      "\n",
      "    accuracy                           0.76      1797\n",
      "   macro avg       0.78      0.76      0.74      1797\n",
      "weighted avg       0.78      0.76      0.74      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y4 = rf2.predict(x_test)\n",
    "print(classification_report(y_test, pred_y4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca444b",
   "metadata": {},
   "source": [
    "## Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d2868",
   "metadata": {},
   "source": [
    "The results indicated that the original samples where more difficult to classify. Performances where both diminishing whether the model was trained on original or generated sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbb365",
   "metadata": {},
   "source": [
    "## 5. Combine train from generated and real samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95067355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([x_train, norm_xtrain])\n",
    "Y = np.concatenate([np.reshape(y_train, -1), y_gentrain])\n",
    "\n",
    "RF = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "RF.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80c4c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real test accuracy :  0.7896494156928213\n",
      "Generated accuracy :  0.9775\n"
     ]
    }
   ],
   "source": [
    "print('Real test accuracy : ', RF.score(x_test, y_test))\n",
    "print('Generated accuracy : ', RF.score(norm_xtest, y_gentest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4906c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       178\n",
      "           1       0.81      0.36      0.50       182\n",
      "           2       0.66      0.89      0.76       177\n",
      "           3       0.73      0.90      0.81       183\n",
      "           4       0.85      0.85      0.85       181\n",
      "           5       0.85      0.77      0.81       182\n",
      "           6       0.83      0.97      0.90       181\n",
      "           7       0.75      0.93      0.83       179\n",
      "           8       0.81      0.51      0.63       174\n",
      "           9       0.81      0.72      0.76       180\n",
      "\n",
      "    accuracy                           0.79      1797\n",
      "   macro avg       0.80      0.79      0.78      1797\n",
      "weighted avg       0.80      0.79      0.78      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y5 = RF.predict(x_test)\n",
    "print('real classification report\\n',classification_report(y_test, pred_y5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "920d6ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      0.93      0.96       180\n",
      "           2       0.99      0.99      0.99       150\n",
      "           3       0.93      1.00      0.96       171\n",
      "           4       1.00      0.95      0.97       142\n",
      "           5       1.00      0.91      0.95       154\n",
      "           6       0.96      1.00      0.98       167\n",
      "           7       0.96      1.00      0.98       155\n",
      "           8       1.00      0.99      1.00       159\n",
      "           9       0.95      1.00      0.98       158\n",
      "\n",
      "    accuracy                           0.98      1600\n",
      "   macro avg       0.98      0.98      0.98      1600\n",
      "weighted avg       0.98      0.98      0.98      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y5g = RF.predict(norm_xtest)\n",
    "print('generated classification report\\n',classification_report(y_gentest, pred_y5g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2819ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "##combine test results\n",
    "x = np.concatenate([x_test, norm_xtest])\n",
    "y = np.concatenate([np.reshape(y_test, -1), y_gentest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9aa89fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Accuracy :  0.8781277597880482\n",
      "Combined classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       342\n",
      "           1       0.94      0.64      0.76       362\n",
      "           2       0.79      0.94      0.86       327\n",
      "           3       0.82      0.95      0.88       354\n",
      "           4       0.92      0.89      0.90       323\n",
      "           5       0.92      0.84      0.88       336\n",
      "           6       0.89      0.99      0.94       348\n",
      "           7       0.84      0.96      0.89       334\n",
      "           8       0.92      0.74      0.82       333\n",
      "           9       0.88      0.85      0.87       338\n",
      "\n",
      "    accuracy                           0.88      3397\n",
      "   macro avg       0.88      0.88      0.88      3397\n",
      "weighted avg       0.88      0.88      0.88      3397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Combined Accuracy : ', RF.score(x, y))\n",
    "pred_y5c = RF.predict(x)\n",
    "print('Combined classification report\\n',classification_report(y, pred_y5c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30285402",
   "metadata": {},
   "source": [
    "# MLP experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a19b6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "def build_model(input_shape=(64,), num_classes=10):\n",
    "    \"\"\"\n",
    "\n",
    "    :param input_shape: shape of input_data\n",
    "    :param num_classes: number of classes\n",
    "    :return: keras.model.sequential compiled with categorical cross-entropy loss\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20210c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37a5b038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3823 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "3823/3823 [==============================] - 1s 215us/sample - loss: 0.2089 - acc: 0.9401 - val_loss: 0.1350 - val_acc: 0.9588\n",
      "Epoch 2/2\n",
      "3823/3823 [==============================] - 1s 215us/sample - loss: 0.1950 - acc: 0.9425 - val_loss: 0.1335 - val_acc: 0.9560\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "epochs=2\n",
    "history = model.fit(train_images, train_y, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9eeb1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_images, test_y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4aeac19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.13348570649624059\n",
      "test accuracy:  0.9560378\n"
     ]
    }
   ],
   "source": [
    "print('test loss: ',score[0])\n",
    "print('test accuracy: ', score[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d0f0e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a979a54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 8, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_oh = model.predict(test_images)\n",
    "y_pred_baseline = y_pred_oh.argmax(axis=-1)\n",
    "y_pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1daa1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       178\n",
      "           1       0.98      0.97      0.98       182\n",
      "           2       1.00      0.93      0.96       177\n",
      "           3       0.99      0.92      0.95       183\n",
      "           4       0.99      0.99      0.99       181\n",
      "           5       0.96      0.97      0.96       182\n",
      "           6       0.96      0.99      0.98       181\n",
      "           7       0.98      0.93      0.95       179\n",
      "           8       0.86      0.91      0.89       174\n",
      "           9       0.89      0.94      0.92       180\n",
      "\n",
      "    accuracy                           0.96      1797\n",
      "   macro avg       0.96      0.96      0.96      1797\n",
      "weighted avg       0.96      0.96      0.96      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MLP classification report\\n',classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a4a76",
   "metadata": {},
   "source": [
    "# Train on combined generated and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "163120fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8623\n",
      "[0.     0.0625 0.375  0.9375 0.75   0.0625 0.     0.     0.     0.4375\n",
      " 1.     0.375  0.375  0.625  0.     0.     0.     0.5    1.     0.125\n",
      " 0.     0.6875 0.125  0.     0.     0.3125 1.     0.1875 0.     0.3125\n",
      " 0.4375 0.     0.     0.4375 0.8125 0.1875 0.     0.5    0.4375 0.\n",
      " 0.     0.25   0.75   0.     0.0625 0.8125 0.3125 0.     0.     0.\n",
      " 0.875  0.5625 0.9375 0.5625 0.     0.     0.     0.     0.375  0.875\n",
      " 0.4375 0.0625 0.     0.    ]\n"
     ]
    }
   ],
   "source": [
    "print(len(Y))\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9549137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 8623 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "8416/8623 [============================>.] - ETA: 0s - loss: 0.6944 - acc: 0.7884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8623/8623 [==============================] - 2s 218us/sample - loss: 0.6864 - acc: 0.7907 - val_loss: 0.3025 - val_acc: 0.9082\n",
      "Epoch 2/2\n",
      "8623/8623 [==============================] - 2s 188us/sample - loss: 0.2602 - acc: 0.9266 - val_loss: 0.2233 - val_acc: 0.9382\n"
     ]
    }
   ],
   "source": [
    "model_aug = build_model()\n",
    "X_train = np.array(X).astype(np.float32) / 16.0\n",
    "Y_oh = np.array(tf.keras.utils.to_categorical(Y, num_classes=10, dtype='float32'))\n",
    "history_aug = model_aug.fit(X_train, Y_oh, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d17acc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined MLP classification report on real samples only.\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       178\n",
      "           1       0.86      0.96      0.90       182\n",
      "           2       0.97      0.99      0.98       177\n",
      "           3       0.95      0.93      0.94       183\n",
      "           4       0.97      0.95      0.96       181\n",
      "           5       0.95      0.97      0.96       182\n",
      "           6       0.97      0.97      0.97       181\n",
      "           7       1.00      0.86      0.92       179\n",
      "           8       0.92      0.82      0.87       174\n",
      "           9       0.84      0.94      0.88       180\n",
      "\n",
      "    accuracy                           0.94      1797\n",
      "   macro avg       0.94      0.94      0.94      1797\n",
      "weighted avg       0.94      0.94      0.94      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_aug_oh = model_aug.predict(test_images)\n",
    "y_pred_aug = y_pred_aug_oh.argmax(axis=-1)\n",
    "print('Combined MLP classification report on real samples only.\\n',classification_report(y_test, y_pred_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07f233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
