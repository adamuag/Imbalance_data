{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3891a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae15b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b636134",
   "metadata": {},
   "source": [
    "## Optical digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f86ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './uci_repos/optical_digits/optdigits.tra'\n",
    "test_file = './uci_repos/optical_digits/optdigits.tes'\n",
    "column = ['pixel_'+str(i) for i in range(64)]\n",
    "column.append('digit_label')\n",
    "train_data = pd.read_csv(train_file, sep=',', header=None, names=column)\n",
    "test_data = pd.read_csv(test_file, sep=',', header=None, names=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a777e21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "      <th>digit_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0        0        0        5       13        9        1        0        0   \n",
       "1        0        0        0       12       13        5        0        0   \n",
       "2        0        0        0        4       15       12        0        0   \n",
       "3        0        0        7       15       13        1        0        0   \n",
       "4        0        0        0        1       11        0        0        0   \n",
       "\n",
       "   pixel_8  pixel_9  ...  pixel_55  pixel_56  pixel_57  pixel_58  pixel_59  \\\n",
       "0        0        0  ...         0         0         0         6        13   \n",
       "1        0        0  ...         0         0         0         0        11   \n",
       "2        0        0  ...         0         0         0         0         3   \n",
       "3        0        8  ...         0         0         0         7        13   \n",
       "4        0        0  ...         0         0         0         0         2   \n",
       "\n",
       "   pixel_60  pixel_61  pixel_62  pixel_63  digit_label  \n",
       "0        10         0         0         0            0  \n",
       "1        16        10         0         0            1  \n",
       "2        11        16         9         0            2  \n",
       "3        13         9         0         0            3  \n",
       "4        16         4         0         0            4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8240c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_all_labels(data, num=100, minor=[]):\n",
    "    # this function is to limit the number of labels that are used\n",
    "    # it returns the indexes according the labels\n",
    "    # data is an array of labels\n",
    "    '''\n",
    "\n",
    "    :param data: array of labels\n",
    "    :param num: number required\n",
    "    :param minor: list of minority indexes\n",
    "    :return: array of labels indexes\n",
    "    '''\n",
    "\n",
    "    labels = np.unique(data)\n",
    "    co_l = []\n",
    "    min_col =[]\n",
    "    if not minor:\n",
    "        for l in labels:\n",
    "            el_l = np.where(np.array(data) == l)\n",
    "            co_l.append(el_l[0])\n",
    "\n",
    "    else:\n",
    "        for l in labels:\n",
    "            if l in minor:\n",
    "                el_l = np.where(np.array(data) == l)\n",
    "                co_l.append((el_l[0])[:num])\n",
    "                min_col.append((el_l[0])[:num])\n",
    "            else:\n",
    "                el_l = np.where(np.array(data) == l)\n",
    "                co_l.append(el_l[0])\n",
    "    return co_l, min_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff98f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data.iloc[:,-1:].copy().to_numpy()\n",
    "train_images = train_data.iloc[:, 0:-1].copy().to_numpy()\n",
    "y_test = test_data.iloc[:,-1:].copy().to_numpy()\n",
    "test_images = test_data.iloc[:, 0:-1].copy().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b911ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 : number of samples : 100\n",
      "class 1 : number of samples : 100\n",
      "class 2 : number of samples : 380\n",
      "class 3 : number of samples : 389\n",
      "class 4 : number of samples : 387\n",
      "class 5 : number of samples : 376\n",
      "class 6 : number of samples : 377\n",
      "class 7 : number of samples : 387\n",
      "class 8 : number of samples : 380\n",
      "class 9 : number of samples : 382\n"
     ]
    }
   ],
   "source": [
    "grouped_labels, min_label = group_all_labels(train_y, 100, [0, 1])\n",
    "gr_data = []\n",
    "gr_labels = [] \n",
    "for index, q in enumerate(grouped_labels):\n",
    "    print('class {} : number of samples : {}'.format(index,len(q)))\n",
    "    for r in q:\n",
    "        gr_data.append(train_images[r])\n",
    "        gr_labels.append(train_y[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe6f415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2346dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image size :  (3258, 64)\n",
      "train y size :  (3258, 10)\n",
      "test image size :  (1797, 64)\n",
      "test y size :  (1797, 10)\n",
      "sample y : [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe55aed9670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_images = [np.reshape(x, (8,8, 1)) for x in train_images ]\n",
    "train_images = np.array(gr_data).astype(np.float32) / 16.0\n",
    "#test_images = [np.reshape(x, (8,8, 1)) for x in test_images ]\n",
    "test_images = np.array(test_images).astype(np.float32) / 16.0\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(gr_labels, num_classes=10, dtype='float32')\n",
    "test_y = tf.keras.utils.to_categorical(y_test, num_classes=10, dtype='float32')\n",
    "print('train image size : ', train_images.shape)\n",
    "print('train y size : ', train_y.shape)\n",
    "print('test image size : ', test_images.shape)\n",
    "print('test y size : ', test_y.shape)\n",
    "print('sample y :', train_y[0])\n",
    "plt.imshow(np.reshape(train_images[100],(8,8)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bb96f",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d0db058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 08:23:39.185316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-11 08:23:39.197629: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-11 08:23:39.198865: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-10-11 08:23:39.200272: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Loss: 6.5e+01\n",
      "Iter: 1000\n",
      "Loss: 2.4e+01\n",
      "Iter: 2000\n",
      "Loss: 2.2e+01\n",
      "Iter: 3000\n",
      "Loss: 2.1e+01\n",
      "Iter: 4000\n",
      "Loss: 2.2e+01\n",
      "Iter: 5000\n",
      "Loss: 2.2e+01\n",
      "Iter: 6000\n",
      "Loss: 2.2e+01\n",
      "Iter: 7000\n",
      "Loss: 2.2e+01\n",
      "Iter: 8000\n",
      "Loss: 2.2e+01\n",
      "Iter: 9000\n",
      "Loss: 2.1e+01\n",
      "Iter: 10000\n",
      "Loss: 2.1e+01\n",
      "Iter: 11000\n",
      "Loss: 2.1e+01\n",
      "Iter: 12000\n",
      "Loss: 2.2e+01\n",
      "Iter: 13000\n",
      "Loss: 2.2e+01\n",
      "Iter: 14000\n",
      "Loss: 2.2e+01\n",
      "Iter: 15000\n",
      "Loss: 2.2e+01\n",
      "Iter: 16000\n",
      "Loss: 2.2e+01\n",
      "Iter: 17000\n",
      "Loss: 2.2e+01\n",
      "Iter: 18000\n",
      "Loss: 2.1e+01\n",
      "Iter: 19000\n",
      "Loss: 2.1e+01\n",
      "Iter: 20000\n",
      "Loss: 2.1e+01\n",
      "Iter: 21000\n",
      "Loss: 2.2e+01\n",
      "Iter: 22000\n",
      "Loss: 2.2e+01\n",
      "Iter: 23000\n",
      "Loss: 2.1e+01\n",
      "Iter: 24000\n",
      "Loss: 2.1e+01\n",
      "Iter: 25000\n",
      "Loss: 2.2e+01\n",
      "Iter: 26000\n",
      "Loss: 2.1e+01\n",
      "Iter: 27000\n",
      "Loss: 2.2e+01\n",
      "Iter: 28000\n",
      "Loss: 2.2e+01\n",
      "Iter: 29000\n",
      "Loss: 2.1e+01\n",
      "Iter: 30000\n",
      "Loss: 2.1e+01\n",
      "Iter: 31000\n",
      "Loss: 2.2e+01\n",
      "Iter: 32000\n",
      "Loss: 2.2e+01\n",
      "Iter: 33000\n",
      "Loss: 2.1e+01\n",
      "Iter: 34000\n",
      "Loss: 2.1e+01\n",
      "Iter: 35000\n",
      "Loss: 2.1e+01\n",
      "Iter: 36000\n",
      "Loss: 2.1e+01\n",
      "Iter: 37000\n",
      "Loss: 2.1e+01\n",
      "Iter: 38000\n",
      "Loss: 2.1e+01\n",
      "Iter: 39000\n",
      "Loss: 2.2e+01\n",
      "Iter: 40000\n",
      "Loss: 2.2e+01\n",
      "Iter: 41000\n",
      "Loss: 2.1e+01\n",
      "Iter: 42000\n",
      "Loss: 2.1e+01\n",
      "Iter: 43000\n",
      "Loss: 2.1e+01\n",
      "Iter: 44000\n",
      "Loss: 2.1e+01\n",
      "Iter: 45000\n",
      "Loss: 2.1e+01\n",
      "Iter: 46000\n",
      "Loss: 2.1e+01\n",
      "Iter: 47000\n",
      "Loss: 2.1e+01\n",
      "Iter: 48000\n",
      "Loss: 2.1e+01\n",
      "Iter: 49000\n",
      "Loss: 2.1e+01\n",
      "Iter: 50000\n",
      "Loss: 2.1e+01\n",
      "Iter: 51000\n",
      "Loss: 2.1e+01\n",
      "Iter: 52000\n",
      "Loss: 2.1e+01\n",
      "Iter: 53000\n",
      "Loss: 2.1e+01\n",
      "Iter: 54000\n",
      "Loss: 2.1e+01\n",
      "Iter: 55000\n",
      "Loss: 2.1e+01\n",
      "Iter: 56000\n",
      "Loss: 2.2e+01\n",
      "Iter: 57000\n",
      "Loss: 2.1e+01\n",
      "Iter: 58000\n",
      "Loss: 2.2e+01\n",
      "Iter: 59000\n",
      "Loss: 2.1e+01\n",
      "Iter: 60000\n",
      "Loss: 2.1e+01\n",
      "Iter: 61000\n",
      "Loss: 2.2e+01\n",
      "Iter: 62000\n",
      "Loss: 2.1e+01\n",
      "Iter: 63000\n",
      "Loss: 2.2e+01\n",
      "Iter: 64000\n",
      "Loss: 2.1e+01\n",
      "Iter: 65000\n",
      "Loss: 2.1e+01\n",
      "Iter: 66000\n",
      "Loss: 2.1e+01\n",
      "Iter: 67000\n",
      "Loss: 2.2e+01\n",
      "Iter: 68000\n",
      "Loss: 2.1e+01\n",
      "Iter: 69000\n",
      "Loss: 2.2e+01\n",
      "Iter: 70000\n",
      "Loss: 2e+01\n",
      "Iter: 71000\n",
      "Loss: 2.3e+01\n",
      "Iter: 72000\n",
      "Loss: 2.2e+01\n",
      "Iter: 73000\n",
      "Loss: 2.1e+01\n",
      "Iter: 74000\n",
      "Loss: 2.1e+01\n",
      "Iter: 75000\n",
      "Loss: 2.1e+01\n",
      "Iter: 76000\n",
      "Loss: 2.1e+01\n",
      "Iter: 77000\n",
      "Loss: 2.1e+01\n",
      "Iter: 78000\n",
      "Loss: 2.1e+01\n",
      "Iter: 79000\n",
      "Loss: 2.1e+01\n",
      "Iter: 80000\n",
      "Loss: 2.1e+01\n",
      "Iter: 81000\n",
      "Loss: 2.2e+01\n",
      "Iter: 82000\n",
      "Loss: 2.1e+01\n",
      "Iter: 83000\n",
      "Loss: 2.1e+01\n",
      "Iter: 84000\n",
      "Loss: 2.1e+01\n",
      "Iter: 85000\n",
      "Loss: 2.1e+01\n",
      "Iter: 86000\n",
      "Loss: 2.2e+01\n",
      "Iter: 87000\n",
      "Loss: 2.1e+01\n",
      "Iter: 88000\n",
      "Loss: 2.1e+01\n",
      "Iter: 89000\n",
      "Loss: 2.1e+01\n",
      "Iter: 90000\n",
      "Loss: 2.1e+01\n",
      "Iter: 91000\n",
      "Loss: 2.2e+01\n",
      "Iter: 92000\n",
      "Loss: 2.1e+01\n",
      "Iter: 93000\n",
      "Loss: 2.1e+01\n",
      "Iter: 94000\n",
      "Loss: 2.2e+01\n",
      "Iter: 95000\n",
      "Loss: 2.1e+01\n",
      "Iter: 96000\n",
      "Loss: 2.1e+01\n",
      "Iter: 97000\n",
      "Loss: 2.1e+01\n",
      "Iter: 98000\n",
      "Loss: 2.1e+01\n",
      "Iter: 99000\n",
      "Loss: 2.1e+01\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "tf.disable_v2_behavior()\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mb_size = 64\n",
    "z_dim = 10\n",
    "X_dim = 64\n",
    "y_dim = 10\n",
    "h_dim = 16\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(8, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(8, 8), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random.normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "\n",
    "# Q(z|X) \n",
    "\n",
    "X = tf.keras.Input(shape=(X_dim,))\n",
    "c = tf.keras.Input(shape=(y_dim,))\n",
    "z = tf.keras.Input(shape=(z_dim,))\n",
    "\n",
    "Q_W1 = tf.Variable(xavier_init([X_dim + y_dim, h_dim]))\n",
    "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "Q_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "Q_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "\n",
    "def Q(X, c):\n",
    "    inputs = tf.concat(axis=1, values=[X, c])\n",
    "    h = tf.nn.relu(tf.matmul(inputs, Q_W1) + Q_b1)\n",
    "    z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n",
    "    z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n",
    "    return z_mu, z_logvar\n",
    "\n",
    "\n",
    "def sample_z(mu, log_var):\n",
    "    eps = tf.random.normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(log_var / 2) * eps\n",
    "\n",
    "\n",
    "# P(X|z)\n",
    "\n",
    "P_W1 = tf.Variable(xavier_init([z_dim + y_dim, h_dim]))\n",
    "P_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "P_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "P_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "\n",
    "def P(z, c):\n",
    "    inputs = tf.concat(axis=1, values=[z, c])\n",
    "    h = tf.nn.relu(tf.matmul(inputs, P_W1) + P_b1)\n",
    "    logits = tf.matmul(h, P_W2) + P_b2\n",
    "    prob = tf.nn.sigmoid(logits)\n",
    "    return prob, logits\n",
    "\n",
    "z_mu, z_logvar = Q(X, c)\n",
    "z_sample = sample_z(z_mu, z_logvar)\n",
    "_, logits = P(z_sample, c)\n",
    "\n",
    "# Sampling from random z\n",
    "X_samples, _ = P(z, c)\n",
    "\n",
    "# E[log P(X|z)]\n",
    "recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X), 1)\n",
    "kl_loss = 0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "\n",
    "# VAE loss\n",
    "vae_loss = tf.reduce_mean(recon_loss + kl_loss)\n",
    "\n",
    "# gradient step\n",
    "solver = tf.compat.v1.train.AdamOptimizer().minimize(vae_loss)\n",
    "sess = tf.compat.v1.Session ()\n",
    "sess.run(\n",
    "tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "# if not os.path.exists('samples_opt_100/'):\n",
    "#     os.makedirs('samples_opt_100/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(100000):\n",
    "    ind = np.random.choice(train_images.shape[0], mb_size)\n",
    "    X_mb = np.array(train_images[ind])\n",
    "    y_mb = np.array(train_y[ind])\n",
    "    \n",
    "    _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb, c: y_mb})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {:.2}'. format(loss))\n",
    "\n",
    "#         y = np.zeros(shape=[64, y_dim])\n",
    "#         y[:, np.random.randint(0, y_dim)] = 1.\n",
    "\n",
    "#         samples = sess.run(X_samples,\n",
    "#                            feed_dict={z: np.random.randn(64, z_dim), c: y})\n",
    "\n",
    "#         fig = plot(samples)\n",
    "#         plt.savefig('samples_opt_100/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "#         i += 1\n",
    "#         plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424bbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### generating sample outputs after training\n",
    "def generate_samples():\n",
    "    samples = []\n",
    "    gen_labels =[]\n",
    "    for r in range(10):\n",
    "        for index in range(2):\n",
    "            gen_labels = gen_labels + [index]*64\n",
    "            y = np.zeros([mb_size, y_dim])\n",
    "            y[range(mb_size), index] = 1\n",
    "            samples.extend(sess.run(X_samples,\n",
    "                                   feed_dict={z: np.random.randn(64, z_dim), c: y}))\n",
    "\n",
    "    gen_samples = np.array(samples)\n",
    "    gen_labels = np.array(gen_labels)\n",
    "    \n",
    "    return gen_samples, gen_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76387c9",
   "metadata": {},
   "source": [
    "# Visualize generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3c7c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280, 64), (1280,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_samples, aug_labels = generate_samples()\n",
    "aug_samples.shape, aug_labels.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5fa24bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5482bd400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(aug_labels[70])\n",
    "plt.imshow(np.reshape(aug_samples[70],(8,8)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35caa411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normiziling pixel between 0..16 similar to the original data.\n",
    "#norm_xtrain = (16*(gen_samples - np.min(gen_samples))/np.ptp(gen_samples)).astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14657c",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "910f934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "def build_model(input_shape=(64,), num_classes=10):\n",
    "    \"\"\"\n",
    "\n",
    "    :param input_shape: shape of input_data\n",
    "    :param num_classes: number of classes\n",
    "    :return: keras.model.sequential compiled with categorical cross-entropy loss\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59ca02",
   "metadata": {},
   "source": [
    "# Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6874de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 3258 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "3258/3258 [==============================] - 1s 252us/sample - loss: 1.4931 - acc: 0.5206 - val_loss: 0.5503 - val_acc: 0.8219\n",
      "Epoch 2/2\n",
      "   8/3258 [..............................] - ETA: 0s - loss: 1.4897 - acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258/3258 [==============================] - 1s 197us/sample - loss: 0.7116 - acc: 0.7744 - val_loss: 0.3504 - val_acc: 0.8859\n",
      "test loss:  0.35044516841935397\n",
      "test accuracy:  0.885921\n",
      "MLP classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       178\n",
      "           1       0.95      0.58      0.72       182\n",
      "           2       0.95      0.92      0.93       177\n",
      "           3       0.87      0.93      0.90       183\n",
      "           4       0.91      0.98      0.94       181\n",
      "           5       0.88      0.96      0.92       182\n",
      "           6       0.97      0.94      0.95       181\n",
      "           7       0.94      0.93      0.94       179\n",
      "           8       0.67      0.86      0.76       174\n",
      "           9       0.81      0.84      0.83       180\n",
      "\n",
      "    accuracy                           0.89      1797\n",
      "   macro avg       0.90      0.89      0.88      1797\n",
      "weighted avg       0.90      0.89      0.88      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "batch_size=8\n",
    "epochs=2\n",
    "history = model.fit(train_images, train_y, batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=(test_images, test_y))\n",
    "score = model.evaluate(test_images, test_y, verbose=0)\n",
    "print('test loss: ',score[0])\n",
    "print('test accuracy: ', score[1] )\n",
    "y_pred_oh = model.predict(test_images)\n",
    "y_pred_baseline = y_pred_oh.argmax(axis=-1)\n",
    "from sklearn.metrics import classification_report\n",
    "print('MLP classification report\\n',classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f3e94",
   "metadata": {},
   "source": [
    "# Augmentation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58216af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4538/4538 [==============================] - 1s 280us/sample - loss: 1.1373 - acc: 0.6514 - val_loss: 0.3943 - val_acc: 0.8809\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 232us/sample - loss: 0.4678 - acc: 0.8599 - val_loss: 0.2965 - val_acc: 0.9054\n",
      "test loss for 0th run:  0.29651229686384145\n",
      "test accuracy for 0th run:  0.9053979\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4376/4538 [===========================>..] - ETA: 0s - loss: 1.1993 - acc: 0.6389"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 2s 351us/sample - loss: 1.1808 - acc: 0.6437 - val_loss: 0.4949 - val_acc: 0.8414\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 238us/sample - loss: 0.5016 - acc: 0.8480 - val_loss: 0.3544 - val_acc: 0.8854\n",
      "test loss for 1th run:  0.3543548403296394\n",
      "test accuracy for 1th run:  0.8853645\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4408/4538 [============================>.] - ETA: 0s - loss: 1.1803 - acc: 0.6343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 2s 361us/sample - loss: 1.1637 - acc: 0.6386 - val_loss: 0.4999 - val_acc: 0.8486\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 293us/sample - loss: 0.5273 - acc: 0.8411 - val_loss: 0.3724 - val_acc: 0.8848\n",
      "test loss for 2th run:  0.37239183796674397\n",
      "test accuracy for 2th run:  0.884808\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4384/4538 [===========================>..] - ETA: 0s - loss: 1.2227 - acc: 0.6282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 1s 294us/sample - loss: 1.2020 - acc: 0.6338 - val_loss: 0.4214 - val_acc: 0.8587\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 251us/sample - loss: 0.4637 - acc: 0.8590 - val_loss: 0.3443 - val_acc: 0.8965\n",
      "test loss for 3th run:  0.34433563323339067\n",
      "test accuracy for 3th run:  0.89649415\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4400/4538 [============================>.] - ETA: 0s - loss: 1.1787 - acc: 0.6473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 1s 261us/sample - loss: 1.1594 - acc: 0.6525 - val_loss: 0.4035 - val_acc: 0.8820\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 191us/sample - loss: 0.4519 - acc: 0.8581 - val_loss: 0.3080 - val_acc: 0.9104\n",
      "test loss for 4th run:  0.3080078124892201\n",
      "test accuracy for 4th run:  0.91040623\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4328/4538 [===========================>..] - ETA: 0s - loss: 1.1472 - acc: 0.6458"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 2s 334us/sample - loss: 1.1216 - acc: 0.6534 - val_loss: 0.4231 - val_acc: 0.8709\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 232us/sample - loss: 0.4809 - acc: 0.8535 - val_loss: 0.2667 - val_acc: 0.9182\n",
      "test loss for 5th run:  0.2666907929595089\n",
      "test accuracy for 5th run:  0.918197\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4472/4538 [============================>.] - ETA: 0s - loss: 1.1455 - acc: 0.6568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 2s 350us/sample - loss: 1.1364 - acc: 0.6589 - val_loss: 0.3828 - val_acc: 0.8854\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 236us/sample - loss: 0.4727 - acc: 0.8607 - val_loss: 0.2880 - val_acc: 0.9093\n",
      "test loss for 6th run:  0.28798717577694505\n",
      "test accuracy for 6th run:  0.9092933\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4464/4538 [============================>.] - ETA: 0s - loss: 1.2191 - acc: 0.6221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 2s 362us/sample - loss: 1.2079 - acc: 0.6258 - val_loss: 0.4446 - val_acc: 0.8748\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 263us/sample - loss: 0.5102 - acc: 0.8424 - val_loss: 0.4283 - val_acc: 0.8781\n",
      "test loss for 7th run:  0.4282519989167576\n",
      "test accuracy for 7th run:  0.8781302\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4488/4538 [============================>.] - ETA: 0s - loss: 1.1162 - acc: 0.6433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 1s 328us/sample - loss: 1.1115 - acc: 0.6450 - val_loss: 0.4048 - val_acc: 0.8776\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 241us/sample - loss: 0.5002 - acc: 0.8446 - val_loss: 0.2541 - val_acc: 0.9204\n",
      "test loss for 8th run:  0.25410825875678456\n",
      "test accuracy for 8th run:  0.9204229\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,034\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 4538 samples, validate on 1797 samples\n",
      "Epoch 1/2\n",
      "4368/4538 [===========================>..] - ETA: 0s - loss: 1.1871 - acc: 0.6330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/adamu/data/projects/notebooks/UCI_encoders/imbalance_venv/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4538/4538 [==============================] - 2s 358us/sample - loss: 1.1704 - acc: 0.6386 - val_loss: 0.3872 - val_acc: 0.8770\n",
      "Epoch 2/2\n",
      "4538/4538 [==============================] - 1s 275us/sample - loss: 0.5129 - acc: 0.8411 - val_loss: 0.3170 - val_acc: 0.9032\n",
      "test loss for 9th run:  0.3170184850419105\n",
      "test accuracy for 9th run:  0.90317196\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for i in range(10):\n",
    "    gen_samples, gen_labels = generate_samples()\n",
    "    gen_y = tf.keras.utils.to_categorical(gen_labels, num_classes=10, dtype='float32')\n",
    "    X = np.concatenate([train_images, gen_samples])\n",
    "    Y = np.concatenate([train_y, gen_y])\n",
    "    model_aug = build_model()\n",
    "    history_aug = model_aug.fit(X, Y, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_y))\n",
    "    \n",
    "    aug_score = model_aug.evaluate(test_images, test_y, verbose=0)\n",
    "    print('test loss for {}th run: '.format(i), aug_score[0])\n",
    "    print('test accuracy for {}th run: '.format(i), aug_score[1] )\n",
    "    \n",
    "    y_pred_aug_oh = model_aug.predict(test_images)\n",
    "    y_pred_aug = y_pred_aug_oh.argmax(axis=-1)\n",
    "    results_list.append(classification_report(y_test, y_pred_aug, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37048cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988365</td>\n",
       "      <td>0.946067</td>\n",
       "      <td>0.966562</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880562</td>\n",
       "      <td>0.747802</td>\n",
       "      <td>0.806863</td>\n",
       "      <td>182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946145</td>\n",
       "      <td>0.922599</td>\n",
       "      <td>0.933711</td>\n",
       "      <td>177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.948845</td>\n",
       "      <td>0.892350</td>\n",
       "      <td>0.918403</td>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.915618</td>\n",
       "      <td>0.953039</td>\n",
       "      <td>0.933575</td>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.879266</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.922740</td>\n",
       "      <td>182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.960471</td>\n",
       "      <td>0.967403</td>\n",
       "      <td>0.963772</td>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.945362</td>\n",
       "      <td>0.876536</td>\n",
       "      <td>0.908705</td>\n",
       "      <td>179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.775652</td>\n",
       "      <td>0.851149</td>\n",
       "      <td>0.808888</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.821834</td>\n",
       "      <td>0.882778</td>\n",
       "      <td>0.848503</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.901169</td>\n",
       "      <td>0.901169</td>\n",
       "      <td>0.901169</td>\n",
       "      <td>0.901169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.906212</td>\n",
       "      <td>0.901115</td>\n",
       "      <td>0.901172</td>\n",
       "      <td>1797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.906516</td>\n",
       "      <td>0.901169</td>\n",
       "      <td>0.901350</td>\n",
       "      <td>1797.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.988365  0.946067  0.966562   178.000000\n",
       "1              0.880562  0.747802  0.806863   182.000000\n",
       "2              0.946145  0.922599  0.933711   177.000000\n",
       "3              0.948845  0.892350  0.918403   183.000000\n",
       "4              0.915618  0.953039  0.933575   181.000000\n",
       "5              0.879266  0.971429  0.922740   182.000000\n",
       "6              0.960471  0.967403  0.963772   181.000000\n",
       "7              0.945362  0.876536  0.908705   179.000000\n",
       "8              0.775652  0.851149  0.808888   174.000000\n",
       "9              0.821834  0.882778  0.848503   180.000000\n",
       "accuracy       0.901169  0.901169  0.901169     0.901169\n",
       "macro avg      0.906212  0.901115  0.901172  1797.000000\n",
       "weighted avg   0.906516  0.901169  0.901350  1797.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "total_df = pd.DataFrame(results_list[0]).transpose()\n",
    "print(len(results_list))\n",
    "for r_dict in results_list[1:]:\n",
    "    temp = pd.DataFrame(r_dict).transpose()\n",
    "    total_df = total_df.add(temp)\n",
    "    \n",
    "average_10x = total_df/10.0\n",
    "average_10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c2ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4726aa8c3a011139ee9eae324612f94ded5d9a6c6a3363e2331a9b86c3055c02"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
